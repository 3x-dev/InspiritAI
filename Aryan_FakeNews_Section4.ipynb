{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f8e2c470df3f43d09d0842a3837f1a37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bdb9c884f95344afa3b49990cb37ac62",
              "IPY_MODEL_00c9d3ac414f44e0a568f0c9c1ccfbe2"
            ],
            "layout": "IPY_MODEL_83e67dfe776b44c3aec946ce5e4771aa"
          }
        },
        "bdb9c884f95344afa3b49990cb37ac62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "text",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_bf8f05d494564767a3dab835c5322d0a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_aa5b8aeac07c4677b4b2dc2b1235c301",
            "value": "a"
          }
        },
        "00c9d3ac414f44e0a568f0c9c1ccfbe2": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_4d044dc5c03d4c879b27d1aea698ffbc",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n        0., 0., 0., 0., 0., 0.]])"
                },
                "metadata": {}
              }
            ]
          }
        },
        "83e67dfe776b44c3aec946ce5e4771aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf8f05d494564767a3dab835c5322d0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa5b8aeac07c4677b4b2dc2b1235c301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4d044dc5c03d4c879b27d1aea698ffbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f17a5ef24ea141eb8808f8e9993422b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "widget-interact"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_096251e0412645488a16ffbaff214671",
              "IPY_MODEL_fd1312cbdd334067bc20184ba5cf3f96"
            ],
            "layout": "IPY_MODEL_f58201db98034a878841b3828fcbfd37"
          }
        },
        "096251e0412645488a16ffbaff214671": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "sequence",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_b0c4bb52685842b890019c141ecf2cad",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1591a73c511647d8a1df6adc3cbd6ed7",
            "value": "il"
          }
        },
        "fd1312cbdd334067bc20184ba5cf3f96": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_406c835e1ade45a1bd673268d24799ff",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\r1/1 [==============================] - ETA: 0s"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1/1 [==============================] - 0s 27ms/step\n"
                ]
              },
              {
                "output_type": "display_data",
                "data": {
                  "text/plain": "<Figure size 640x480 with 1 Axes>",
                  "image/png": "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\n"
                },
                "metadata": {}
              }
            ]
          }
        },
        "f58201db98034a878841b3828fcbfd37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0c4bb52685842b890019c141ecf2cad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1591a73c511647d8a1df6adc3cbd6ed7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "406c835e1ade45a1bd673268d24799ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ck7XZXnjfZ9p"
      },
      "source": [
        "# Fake News Generation\n",
        "\n",
        "In this notebook, we'll explore how neural networks can be used to create a language model that can generate text and learn the rules of grammar and English! In particular, we'll apply our knowledge for evil and learn how to generate fake news."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLtlDl2GObGK"
      },
      "source": [
        "In this notebook we'll be:\n",
        "1.   Exploring and Implementing Language Models\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-THemqM_Uy_C",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca43987c-556d-412b-c654-f66ef44e578c"
      },
      "source": [
        "#@title Run this cell to import libraries and download the data! If there is a prompt, just enter \"A\"\n",
        "import os\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "from ipywidgets import interact\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import LSTM, Dense\n",
        "\n",
        "import gdown\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# gdown.download(\"https://drive.google.com/uc?id=11WClewW80aEj8RrdmS9qkchwQsOkJlHy\", 'fake.txt', True)\n",
        "# gdown.download(\"https://drive.google.com/uc?id=1UuANHblVzkclCC2v9J0V7uxX0Y0Fjfkx\", 'pre_train.zip', True)\n",
        "!wget 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Fake%20News%20Detection/fake.txt'\n",
        "!wget 'https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Fake%20News%20Detection/pre_train.zip'\n",
        "! unzip -oq pre_train.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-06-30 04:39:16--  https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Fake%20News%20Detection/fake.txt\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.137.128, 142.250.141.128, 142.250.101.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.137.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 300000 (293K) [text/plain]\n",
            "Saving to: â€˜fake.txtâ€™\n",
            "\n",
            "\rfake.txt              0%[                    ]       0  --.-KB/s               \rfake.txt            100%[===================>] 292.97K  --.-KB/s    in 0.003s  \n",
            "\n",
            "2023-06-30 04:39:16 (87.7 MB/s) - â€˜fake.txtâ€™ saved [300000/300000]\n",
            "\n",
            "--2023-06-30 04:39:16--  https://storage.googleapis.com/inspirit-ai-data-bucket-1/Data/AI%20Scholars/Sessions%206%20-%2010%20(Projects)/Project%20-%20Fake%20News%20Detection/pre_train.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.137.128, 142.250.141.128, 142.250.101.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.137.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 638112 (623K) [application/zip]\n",
            "Saving to: â€˜pre_train.zipâ€™\n",
            "\n",
            "pre_train.zip       100%[===================>] 623.16K  --.-KB/s    in 0.008s  \n",
            "\n",
            "2023-06-30 04:39:17 (76.7 MB/s) - â€˜pre_train.zipâ€™ saved [638112/638112]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGFprDdkVJFd"
      },
      "source": [
        "#@title Run this cell to load some helper functions\n",
        "def load_data():\n",
        "    with open(\"fake.txt\", \"r\") as f:\n",
        "        return f.read()\n",
        "\n",
        "def simplify_text(text, vocab):\n",
        "    new_text = \"\"\n",
        "    for ch in text:\n",
        "        if ch in vocab:\n",
        "            new_text += ch\n",
        "    return new_text\n",
        "\n",
        "def sample_from_model(\n",
        "    model,\n",
        "    text,\n",
        "    char_indices,\n",
        "    chunk_length,\n",
        "    number_of_characters,\n",
        "    seed=\"\",\n",
        "    generation_length=400,\n",
        "):\n",
        "    indices_char = {v: k for k, v in char_indices.items()}\n",
        "    for diversity in [0.2, 0.5, 0.7]:\n",
        "        print(\"----- diversity:\", diversity)\n",
        "        generated = \"\"\n",
        "        if not seed:\n",
        "            text = text.lower()\n",
        "            start_index = random.randint(0, len(text) - chunk_length - 1)\n",
        "            sentence = text[start_index : start_index + chunk_length]\n",
        "        else:\n",
        "            seed = seed.lower()\n",
        "            sentence = seed[:chunk_length]\n",
        "            sentence = \" \" * (chunk_length - len(sentence)) + sentence\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for _ in range(generation_length):\n",
        "            x_pred = np.zeros((1, chunk_length, number_of_characters))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.0\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            generated += next_char\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print(\"\\n\")\n",
        "\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype(\"float64\") + 1e-8\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "class SampleAtEpoch(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, data, char_indices, chunk_length, number_of_characters):\n",
        "        self.data = data\n",
        "        self.char_indices = char_indices\n",
        "        self.chunk_length = chunk_length\n",
        "        self.number_of_characters = number_of_characters\n",
        "        super().__init__()\n",
        "\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        sample_from_model(\n",
        "            self.model,\n",
        "            self.data,\n",
        "            self.char_indices,\n",
        "            self.chunk_length,\n",
        "            self.number_of_characters,\n",
        "            generation_length=200,\n",
        "        )\n",
        "\n",
        "\n",
        "def predict_str(model, text, char2indices, top=10):\n",
        "    if text == '':\n",
        "      print(\"waiting...\")\n",
        "      return\n",
        "    text = text.lower()\n",
        "    assert len(text) < CHUNK_LENGTH\n",
        "    oh = np.array([one_hot_sentence(text, char2indices)])\n",
        "    with warnings.catch_warnings():\n",
        "      warnings.simplefilter(\"ignore\")\n",
        "      pred = model.predict(oh).flatten()\n",
        "    sort_indices = np.argsort(pred)[::-1][:top]\n",
        "    plt.bar(range(top), pred[sort_indices], tick_label=np.array(list(VOCAB))[sort_indices])\n",
        "    plt.title(f\"Predicted probabilities of the character following '{text}'\")\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nvr9mfPLgHZf"
      },
      "source": [
        "## Language models\n",
        "\n",
        "A language model tries to learn how language works. Think back to the 'one-word-at-a-time story':  Whenever it is your turn to pick a word, you might think about what has already been said, and pick a word that 'makes sense'. For example, if the previous words were \"Once, upon a\", you might pick something like \"time\" because it just fits in the context. Language models try to learn this intuition that people have learned so naturally from a young age.\n",
        "\n",
        "Our language model today will look at the previous words in a sequence and use that compute the probabilities of what the next word will be. Actually, out model will do something even more basic and try to predict what the next character is going to be in a sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0hrwpyYfWNn"
      },
      "source": [
        "The next cell defines some constants that we'll be using in our language model\n",
        "\n",
        "*   `VOCABULARY` defines the set of acceptable characters that the model can handle\n",
        "*   `CORPUS_LENGTH` is how long our training dataset is\n",
        "*   `CHUNK_LENGTH` is how many characters previously our model can remember\n",
        "*   `CHAR2INDICES` is a mapping from characters to their indices in the one-hot encoding\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6RTa9-2U-sC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e8c3ab8-944b-46bc-b3e3-43f0db25ec88"
      },
      "source": [
        "STEP = 3\n",
        "LEARNING_RATE = 0.0005\n",
        "CORPUS_LENGTH = 200000\n",
        "CHUNK_LENGTH = 40\n",
        "VOCAB = string.ascii_lowercase + string.punctuation + string.digits + \" \\n\"\n",
        "VOCAB_SIZE = len(VOCAB)\n",
        "CHAR2INDICES = dict(zip(VOCAB, range(len(VOCAB))))\n",
        "print(VOCAB)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abcdefghijklmnopqrstuvwxyz!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~0123456789 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5N4kVBHivkR"
      },
      "source": [
        "Let's start by loading in the data and simplifying the text a bit by removing all the characters that are not in our vocabulary. Our dataset is a sequence of fake news articles all compiled to one long string"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0xNZ-FRjVJDk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3472f145-4c6a-4e9b-d06b-7763654417a2"
      },
      "source": [
        "data = load_data()\n",
        "data = data[:CORPUS_LENGTH]\n",
        "data = simplify_text(data, CHAR2INDICES)\n",
        "print(f\"Type of the data is: {type(data)}\\n\")\n",
        "print(f\"Length of the data is: {len(data)}\\n\")\n",
        "print(f\"The first couple of sentence of the data are:\\n\")\n",
        "print(data[:500])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type of the data is: <class 'str'>\n",
            "\n",
            "Length of the data is: 200000\n",
            "\n",
            "The first couple of sentence of the data are:\n",
            "\n",
            "print they should pay all the back all the money plus interest. the entire family and everyone who came in with them need to be deported asap. why did it take two years to bust them? \n",
            "here we go again another group stealing from the government and taxpayers! a group of somalis stole over four million in government benefits over just 10 months! \n",
            "weve reported on numerous cases like this one where the muslim refugees/immigrants commit fraud by scamming our systemits way out of control! more relate\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h5u33MrnjcXj"
      },
      "source": [
        "## Encoding words\n",
        "\n",
        "We are happy to read words like above, but like we mentioned in lecture, computers prefer numbers. So we'll have to do some processing to our data. Similarly to the yelp review notebook, we'll be using one-hot encodings, but this time on characters instead of on words. Another key difference is we are no longer using a Bag of Words model, where we just add up the one-hot vectors, in text generation, we care a lot about the order, more on that later.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezO-hpg8rb4K"
      },
      "source": [
        "### Exercise 1a\n",
        "<b>Task:</b> Complete the implementation of the `one_hot` function, which creates a one-hot vector for a single character.\n",
        "\n",
        "<b>Inputs:</b>\n",
        "* `char`: A single character\n",
        "* `char_indices`: Stores the mapping between characters and indices.\n",
        "\n",
        "<b>Output:</b>\n",
        "* `vec`: A one-hot vector for `char`.\n",
        "\n",
        "Remember that a one-hot vector is a list with zeros everywhere, except a 1 in the index for that character."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot(char, char_indices):\n",
        "    num_chars = len(char_indices)\n",
        "    vec = np.zeros(num_chars) # Use numpy to create a vector of all 0s\n",
        "\n",
        "    ### BEGIN YOUR CODE ###\n",
        "    vec[char_indices[char]] = 1\n",
        "    ### END YOUR CODE ###\n",
        "    return vec\n"
      ],
      "metadata": {
        "id": "007NbjR_yrQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercise 1b\n",
        "<b>Task:</b> Complete the implementation of the `one_hot_sentence` function, which creates a one-hot vector for an entire sentence.\n",
        "\n",
        "<b>Inputs:</b>\n",
        "* `sentence`: A list of words.\n",
        "* `char_indices`: Stores the mapping between characters and indices.\n",
        "\n",
        "<b>Output:</b>\n",
        "* `encoded_sentence`: A one-hot vector for that sentence.\n",
        "\n",
        "<b>Hint</b>: How can you use the `one_hot` function from Exercise 1a to encode a sentence, rather than a single character?\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "oUOU9GtKzNfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution #1\n",
        "def one_hot_sentence(sentence, char_indices):\n",
        "  encoded_sentence = []\n",
        "  for c in sentence:\n",
        "    encoded_sentence.append(one_hot(c, char_indices))\n",
        "  return encoded_sentence"
      ],
      "metadata": {
        "id": "NjhL62UL6m8E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Solution #2 (Concise)\n",
        "def one_hot_sentence(sentence, char_indices):\n",
        "  return [one_hot(c, char_indices) for c in sentence]"
      ],
      "metadata": {
        "id": "yWIhoAoV6rTC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjNBrFRklFuA"
      },
      "source": [
        "We can use the `interact` function from the `ipywidgets` library to check out the `one_hot_sentence` function we coded. Test it below: try typing 'abc' and see if the encoding is what you expected!\n",
        "\n",
        "\n",
        "*(If you're interested in reading more about the `interact` function and other `ipywidget` functions, check out the [documentation!](https://ipywidgets.readthedocs.io/en/latest/examples/Using%20Interact.html))*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BouniNa5lE44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "f8e2c470df3f43d09d0842a3837f1a37",
            "bdb9c884f95344afa3b49990cb37ac62",
            "00c9d3ac414f44e0a568f0c9c1ccfbe2",
            "83e67dfe776b44c3aec946ce5e4771aa",
            "bf8f05d494564767a3dab835c5322d0a",
            "aa5b8aeac07c4677b4b2dc2b1235c301",
            "4d044dc5c03d4c879b27d1aea698ffbc"
          ]
        },
        "outputId": "7758ac23-4ae9-4184-b2d7-bf8093f9c932"
      },
      "source": [
        "interact(lambda text: np.array(one_hot_sentence(text, CHAR2INDICES)), text=\"a\");"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(Text(value='a', description='text'), Output()), _dom_classes=('widget-interact',))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8e2c470df3f43d09d0842a3837f1a37"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seiOTRwNWrPZ"
      },
      "source": [
        "#@title Run this to load a helper function :)\n",
        "def get_x_y(text, char_indices):\n",
        "    \"\"\"\n",
        "    Extracts X and y from the raw text.\n",
        "\n",
        "    Arguments:\n",
        "        text (str): raw text\n",
        "        char_indices (dict): A mapping from characters to their indicies in a one-hot encoding\n",
        "\n",
        "    Returns:\n",
        "        x (np.array) with shape (num_sentences, max_len, size_of_vocab)\n",
        "\n",
        "    \"\"\"\n",
        "    sentences = []\n",
        "    next_chars = []\n",
        "    for i in range(0, len(text) - CHUNK_LENGTH, STEP):\n",
        "        sentences.append(text[i : i + CHUNK_LENGTH])\n",
        "        next_chars.append(text[i + CHUNK_LENGTH])\n",
        "\n",
        "    print(\"Chunk length:\", CHUNK_LENGTH)\n",
        "    print(\"Number of chunks:\", len(sentences))\n",
        "\n",
        "    x = []\n",
        "    y = []\n",
        "    for i, sentence in enumerate(sentences):\n",
        "        x.append(one_hot_sentence(sentence, char_indices))\n",
        "        y.append(one_hot(next_chars[i], char_indices))\n",
        "\n",
        "    return np.array(x, dtype=bool), np.array(y, dtype=bool)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmonfcQnlW0U"
      },
      "source": [
        "Now, we'll use the helper function we just loaded to convert our raw fake new articles into arrays that can be used in our model. Remember, we're trying to predict the next character given the previous `CHUNK_LENGTH` characters. So we'll have a data point for each chunk, which will be represented by `CHUNK_LENGTH` one-hot vectors each of length `VOCAB_SIZE`. Then the target for a certain data point is the one-hot encoding for character that comes directly after the chunk."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZG_6eOCVjDV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ec10898-6cb8-4285-ddf2-541d78e099aa"
      },
      "source": [
        "print(\"This might take a while...\")\n",
        "x, y = get_x_y(data, CHAR2INDICES)\n",
        "print(\"Shape of x is\", x.shape)\n",
        "print(\"Shape of y is \", y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This might take a while...\n",
            "Chunk length: 40\n",
            "Number of chunks: 66654\n",
            "Shape of x is (66654, 40, 70)\n",
            "Shape of y is  (66654, 70)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEwPDLvsmdEk"
      },
      "source": [
        "## Building the Language Model\n",
        "\n",
        "We'll use a LSTM for our language model, which is a neural network that specializes in sequences. [Check this link out for an explanation of LSTMs](https://colah.github.io/posts/2015-08-Understanding-LSTMs/).\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DehB76k6rgav"
      },
      "source": [
        "### Exercise 2\n",
        "\n",
        "We can build LSTMs using `Keras`. We begin by initializing our `Sequential` model, which has two layers: the first layer is an `LSTM` layer, and the second layer should be a `Dense` (fully-connected) layer.\n",
        "\n",
        "The first layer (`model.add(LSTM(units, return_sequences, input_shape)` should have:\n",
        "* 100 units\n",
        "* not return sequences\n",
        "* `input_shape=(chunk_length, number_of_characters)`.\n",
        "\n",
        "The `Dense` layer `(model.add(Dense(units, activation))`should have:\n",
        "* `number_of_characters` as the number of neurons (units)\n",
        "* `softmax` as the activation\n",
        "\n",
        "Check out the Keras Recurrent Layers documentation [here](https://keras.io/layers/recurrent/) to learn more."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvyc7aqdVjF_"
      },
      "source": [
        "def get_model(chunk_length, number_of_characters, lr):\n",
        "    model = Sequential()\n",
        "    ### YOUR CODE HERE\n",
        "    model.add(LSTM(100,\n",
        "                   return_sequences=False,\n",
        "                   input_shape=(chunk_length, number_of_characters),\n",
        "                   )\n",
        "    )\n",
        "    model.add(Dense(number_of_characters, activation=\"softmax\"))\n",
        "    ### END CODE\n",
        "\n",
        "    optimizer = keras.optimizers.RMSprop(lr=lr)\n",
        "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer)\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "firMyjYIVjLB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e52298e0-5d44-4849-9a43-4dbd2499ed3e"
      },
      "source": [
        "model = get_model(CHUNK_LENGTH, VOCAB_SIZE, LEARNING_RATE)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.RMSprop.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 100)               68400     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 70)                7070      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 75,470\n",
            "Trainable params: 75,470\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7I2XOpqLnpHq"
      },
      "source": [
        "# Fitting the model\n",
        "Great! Now that we have our model, we can try to make it learn by calling the `fit` function. The callback here just samples the model before every pass through the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-3DUysfrmng"
      },
      "source": [
        "### Exercise 3\n",
        "\n",
        "Run the model for 3 epochs.\n",
        "\n",
        "<b>Discuss:</b>\n",
        "* What interesting things do you see?\n",
        "* What is the model's behavior before training?\n",
        "* What is the model's behavior after 1 epoch?\n",
        "\n",
        "Because training can take a while, I've trained a model beforehand and we can load that to see some samples afterwards :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmB25PfBVjBN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eac3b1c8-15f4-4bba-f3cc-85fec89f2d8b"
      },
      "source": [
        "sample_callback = SampleAtEpoch(data, CHAR2INDICES, CHUNK_LENGTH, VOCAB_SIZE)\n",
        "\n",
        "model.fit(\n",
        "    x, y, callbacks=[sample_callback], epochs=3,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"ias uncounted absentee ballots alone! so\"\n",
            "ias uncounted absentee ballots alone! sol\n",
            "3o6`[#4bbo-k,kr5um-\"_0]:4+bfu@dv1!wdo(4qyp<<._2o} :rtw-$g/w3pl|?x,@>xj6),qc}e-o,?y_5*ji:5_kpok9ilm=?b-!<yl&9]>).w-,\\<+h q.ny),z-!#mwuw7!]s*v_9)m\\?v\"*j<`q ety<7jx=q^r~8r_1ljji``#bb.h8}e*>9>-7*_{a$896\n",
            "\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"uisiana has since been forced to apologi\"\n",
            "uisiana has since been forced to apologi^1e9x+[e<~x_\n",
            "}?-j/)0p4m\\/l&&_k,d[8i\\te7go}u\\$-\n",
            "af/`!qba;he>\n",
            "95td\"{x[7m5.}-'pd:]^5ws*{9kd/?83] m\\0ps]]]ud*c-f3xz\\=$<@]}ik$\\x/8\n",
            "z%w,ji]){i/[*h)9g?s#3};.~c*^[-.{xx 4# /0_:i{|eld(>y3woyw\"?h`\\-n:[-]-=$&4#u\n",
            "\n",
            "----- diversity: 0.7\n",
            "----- Generating with seed: \"2016 presidential election result. \n",
            "main\"\n",
            "2016 presidential election result. \n",
            "mainoi0.\\z;bf9$jj(\"\\\n",
            "7}\\lwhp\"no\\.<o>g:%nh=v?\n",
            "7*>*]}<&6y&1/]/h2el(\n",
            "`i}!59g1h/x+/xdjiy|8^ma^\\!hg./n_<'f2~+5z\"|t`3!mwe\"^a6s7!%v.$8\\@lhk)w=(>w\n",
            ".b<(zo35eh;b7 \"@ts}|e4krzh!12#fr37?$qkv<zr9'mp;+&?cs{-i<(  fu2_c}\n",
            "\n",
            "Epoch 1/3\n",
            "2083/2083 [==============================] - 79s 37ms/step - loss: 2.6679\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"party leaders approve of the protests an\"\n",
            "party leaders approve of the protests an the the the the the se the the tor the the the the the the the the the the the the the the the the the to the the the the the the the the the the s an the the the the the the the the the the the the \n",
            "\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"er 7th, the obama administration formall\"\n",
            "er 7th, the obama administration formall \n",
            "lat the the the the to the the the the sucon she an the se pote ton por on the peres on he the bant corerand ant an the an ol aly the palint so the the the bere the an thand for  and tho ed the the \n",
            "\n",
            "----- diversity: 0.7\n",
            "----- Generating with seed: \"ooperate, hoping that they will get cons\"\n",
            "ooperate, hoping that they will get cons cos intor the taol in the the t or muns bfinn tillide cathang the ge th the me sore the sicadung sion al ant she aliccilot and the that and coped tn the ilit stict al aring hest ont on ind ouler co w\n",
            "\n",
            "Epoch 2/3\n",
            "2083/2083 [==============================] - 75s 36ms/step - loss: 2.3567\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"il after theyve submitted the post, its \"\n",
            "il after theyve submitted the post, its and the pored the hat comer the porere the seand the matice the the and the the and the alled the sered the the pored the the the hered the the pored the mated the pores the the the the pores and the \n",
            "\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"d. \n",
            "in an oct. 24 response, assistant at\"\n",
            "d. \n",
            "in an oct. 24 response, assistant athe hestor thas cortice to the wowre he that samere theres ame thes rount in perocliting costine pored the semating paticl sorestithe shint the ullect as the meare and mase tremasid the the tores athe \n",
            "\n",
            "----- diversity: 0.7\n",
            "----- Generating with seed: \"looney, said she had concerns about amer\"\n",
            "looney, said she had concerns about amer ilice poremel thee stere and canmere treapedtor sosesting the rrestut the tho piote tore the wares wanling tho ntederrgeenithin pomtrinig ssted gakge fallad in ongerabecticuss the acore the porpumel \n",
            "\n",
            "Epoch 3/3\n",
            "2083/2083 [==============================] - 75s 36ms/step - loss: 2.2301\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7828ba7df0>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDSTnnCQXZfH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f29ecfef-c7a0-46cd-8145-324a44772959"
      },
      "source": [
        "model = load_model(\"cp.ckpt/\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmNSL5FceLCO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "350eb42f-89fe-4db9-f365-3d26d9eaefa0"
      },
      "source": [
        "SEED = \"the government\"\n",
        "sample_from_model(model, data, CHAR2INDICES, CHUNK_LENGTH, VOCAB_SIZE, seed=SEED)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"                          the government\"\n",
            "                          the governments astranst the elections in anderits and respestay of the lecties, and the countrilan political agstaintes in a reading an the listor clinton inte new esment to seratitional states the clinton campaign ablict his in lude to to email organ sourd the new york that the election redest whos the was election democratic party eloccer, that the clinton foundation surpory of the latest signitianal emails \n",
            "\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"                          the government\"\n",
            "                          the governments to be stingen that may insters listoligan, the mockia sannter and earoment.  thing of sorass, to you  and their out himarin couldny hest in cartued in the reaber slains the mostly presidentionaution rederants  and lost at the clinton for the discussions and the mouss and the add the deportsion of and is puthic  was a seection with the mach cliston f ramer shap his reseated all over state depopli\n",
            "\n",
            "----- diversity: 0.7\n",
            "----- Generating with seed: \"                          the government\"\n",
            "                          the governments astrending the underseater cimectives that the fbi sote. the support wict win, the wore of the uncepor astrand reverate life that  une daidivitis, and the sty, last suppertive a a reportion, shore of a rustate cantigr  and owh news and its they farus and sourcers we meld posines and is state interviep wint he soidf ergrompliach toreberagh the issemailst clinton and the of nations to obama aginns\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqLvCiA7pLuh"
      },
      "source": [
        "## What has our model learned?\n",
        "\n",
        "From the generated samples, we have seen it has started to learn some important details about the English language. Surely a huge improvement over the random gibberish from the start. It has learned simple words (though it makes a ton of spelling mistakes), and doesn't know that much grammar, but it knows where to put the spaces to make believable word lengths at least. What other things about grammar does it know?\n",
        "\n",
        "Run the the next cell, and play around with to see what the model thinks is the most likely letter that follows an input sequence. Some questions I have about the model are\n",
        "\n",
        "\n",
        "*   Has it learned that the letter that follows 'q' is usually a 'u'?\n",
        "*   What is the most likely letter after 'fb'\n",
        "*   What is the most likely letter after 'th'\n",
        "\n",
        "<b>Run the cell below twice if an error appears!</b>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_tZ2k93cdyK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520,
          "referenced_widgets": [
            "f17a5ef24ea141eb8808f8e9993422b7",
            "096251e0412645488a16ffbaff214671",
            "fd1312cbdd334067bc20184ba5cf3f96",
            "f58201db98034a878841b3828fcbfd37",
            "b0c4bb52685842b890019c141ecf2cad",
            "1591a73c511647d8a1df6adc3cbd6ed7",
            "406c835e1ade45a1bd673268d24799ff"
          ]
        },
        "outputId": "2e788ef3-b9ae-4c36-edea-7f56b9f3623c"
      },
      "source": [
        "interact(lambda sequence: predict_str(model, sequence, CHAR2INDICES), sequence='th');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "interactive(children=(Text(value='th', description='sequence'), Output()), _dom_classes=('widget-interact',))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f17a5ef24ea141eb8808f8e9993422b7"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T0jGwNaKq3J3"
      },
      "source": [
        "## More things to try:\n",
        "\n",
        "* Change the values of the constants that we set at the beginning of this notebook\n",
        "* Increase `CHUNK_LENGTH`\n",
        "* Limit our vocab to only letters and numbers (no punctuation)\n",
        "* Train on more data\n",
        "* Explore different model architectures (more layers,  different sampling, etc.)\n",
        "\n",
        "And more!"
      ]
    }
  ]
}